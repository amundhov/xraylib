#!/usr/bin/env python

import numpy as np
import os, optparse, h5py, fabio

import xraylib
from xraylib import f2w, files, utils

try:
    import pyFAI
except ImportError:
    pyFAI = None

DARKCURRENT_DATA_SET = '/xraylib/darkcurrent'

class Integrator(utils.Script):
    def __init__(self):
        super(Integrator, self).__init__()
        self.description = """
        Integrate diffraction images and assemble into dataset.
        Experiment parameters are assumed to be separated by underscore

        E.g.  NAME_xxx_yyy_zzz.edf

        will produce a data set with powder profiles in dimensions x,y,z.
        """
        self.usage="Usage: <options> --data-prefix=/mnt/data/../EXPERIMENT_..."

    def parser_setup(self):
        super(Integrator, self).parser_setup()

        input_group = optparse.OptionGroup(self.parser, "Input options")
        input_group.add_option("--data-prefix", dest="data_path",
                          metavar="/path/IMAGE_xyz_",
                          help="Integrate files starting with this path.")
        #input_group.add_option("--dark-prefix", dest="dark_prefix",
        #                  metavar="/path/DARK_xyz_",
        #                  help="Use dark noise files starting with this path.")
        input_group.add_option("--dark", dest="dark",
                          help="Dark noise image.")
        input_group.add_option("-p", "--ponit", dest="poni_file",
                          help="Name of poni file with detector geometry.")

        output_group = optparse.OptionGroup(self.parser, "Output options")
        output_group.add_option("-o", "--out", dest="outfile",
                          help="File to save integrated dataset.", metavar="FILE", default="diff_tomo.h5")
        output_group.add_option("--data-set", dest="data_set",
                          help="Location to save data set.", metavar="STRING", default="/xraylib/diff_tomo")

        self.parser.add_option_group(input_group)
        self.parser.add_option_group(output_group)

        # TODO make sure reshaping the output file is done correctly
        self.parser.add_option("--skip", dest="skip_file",
                          help="Skip processing to file x.",
                          metavar="x")
        self.parser.add_option("--disable-gpu",
                          action="store_true", dest="disable_gpu", default=False,
                          help="Disable GPU for integration.")

    @utils.Script.timed
    def parse(self):
        super(Integrator, self).parse()

        if not self.options.data_path:
            self.parser.error("Please specify the prefix for your data files")

        (self.directory,file_prefix) = os.path.split(os.path.expanduser(self.options.data_path))
        if self.directory == '':
            directory = '.'
        else:
            directory = self.directory
        # FIXME sort files
        self.files = [ os.path.join(directory,o) for o in os.listdir(directory) if o.startswith(file_prefix) ]
        self.file_names = [ o for o in os.listdir(directory) if o.startswith(file_prefix) ]

        if all([os.path.splitext(file_path)[1] == '.edf' for file_path in self.args]):
            self.edf_only = True
        else:
            self.edf_only = False

        if len(self.options.data_set.split('/')) < 2:
            self.parser.error("Dataset should be on the form '/group_name/data_set'.")

        self.parameters = [ [int(parm) for parm in os.path.splitext(o)[0].split('_')[1:]] for o in self.file_names ]
        parametersT = np.array(self.parameters).T

        self.number_of_parameters = parametersT.shape[0]
        self.print_verbose('Number of parameters: ', self.number_of_parameters)

        min_indices = parametersT.argmin(axis=1)
        max_indices = parametersT.argmax(axis=1)

        parameter_interval = np.array([ [ parametersT[i][min_indices[i]], parametersT[i][max_indices[i]] ] for i in xrange(0,self.number_of_parameters) ])
        self.parameter_count  = [ j-i+1 for i,j in parameter_interval ]
        self.parameter_min = parameter_interval.T[0]

        if self.options.poni_file and os.path.exists(self.options.poni_file):
            self.integrator = pyFAI.load(self.options.poni_file)
        else:
            self.parser.error("Need poni file to set up Azimuthal integrator.")

        if os.path.exists(self.options.dark):
            self.dark = files.ImageFile(self.options.dark).getImage()
            # FIXME pyFAI doesn't subtract darkcurrent as of june 2013
            #self.integrator.darkcurrent = self.dark 


    @utils.Script.timed
    def create_dataset(self):
        self.print_verbose("Creating dataset")

        # FIXME remove once confirmed
        self.det = f2w.Perkin()
        self.det.setdist(900)
        self.det.setorigin(np.array([197.2052035 ,  211.88159321]))
        self.det.settilt(np.array([-0.17446037,  0.01906504]))
        (two_theta, self.darkcurrent_profile) = self.det.integrate(self.dark)

        self.print_verbose("Data set size:", (2,) + tuple(self.parameter_count) + self.darkcurrent_profile.shape,)

        self.hd5 = h5py.File(self.options.outfile)
        group = self.hd5.require_group(os.path.dirname(self.options.data_set))
        self.dataset = group.require_dataset(
                           name=os.path.basename(self.options.data_set),
                           # FIXME remove (2,) when done testing
                           shape=(2,) + tuple(self.parameter_count) + self.darkcurrent_profile.shape,
                           chunks=(2,) + tuple(self.parameter_count) + (1,),
                           dtype="float32"
                        )
        darkcurrent = group.require_dataset(
                           name=DARKCURRENT_DATA_SET,
                           shape=self.darkcurrent_profile.shape,
                           dtype="float32"
        )
        darkcurrent[:] = self.darkcurrent_profile

    @utils.Script.timed
    def integrate_and_assemble(self):
        self.print_verbose("Integrating ", len(self.parameters), "images")

        i=0
        for image in files.ImageSequence(self.files):
            index = self.parameters[i]-self.parameter_min
            self.print_verbose("Integrating ", self.file_names[i], index)
            (tth,result) = self.det.integrate(image,)
            result = result - self.darkcurrent_profile
            self.dataset[(0,)+tuple(index)] = result.astype(np.float32)
            self.print_verbose("pyFAI")
            if not self.options.disable_gpu:
                tth, I = self.integrator.xrpd_LUT_OCL(
                            image-self.dark,
                            self.darkcurrent_profile.shape[0],
                            safe=False,
                            devicetype="gpu")
            else:
                tth, I = self.integrator.xrpd_LUT(image-self.dark, self.darkcurrent_profile.shape[0], safe=False)

            self.dataset[(1,)+tuple(index)] = I
            i=i+1

    @utils.Script.timed
    def output(self):
        self.hd5.close()

if __name__ == '__main__':
    intg = Integrator()

    intg.parser_setup()
    intg.parse()
    intg.create_dataset()
    intg.integrate_and_assemble()
    intg.output()
    intg.print_timings()

