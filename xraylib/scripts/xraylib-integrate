#!/usr/bin/env python

import numpy as np
import os, sys, optparse
import itertools, threading, Queue
import h5py, fabio

import xraylib
from xraylib import f2w, files, utils

try:
    import pyFAI
except ImportError:
    pyFAI = None

class Integrator(utils.Script):
    def __init__(self):
        super(Integrator, self).__init__()
        self.description = """
        Integrate diffraction images and assemble into dataset.
        Experiment parameters are assumed to be separated by underscore

        E.g.  NAME_xxx_yyy_zzz.edf

        will produce a data set with powder profiles in dimensions x,y,z.
        """
        self.usage="Usage: <options> --data-prefix=/mnt/data/../EXPERIMENT_..."

        self.disable_threads    = False
        self.diable_fast_edf    = False
        self.disable_gpu        = False

        self.integration_points = 1500

    def parser_setup(self):
        super(Integrator, self).parser_setup()

        input_group = optparse.OptionGroup(self.parser, "Input options")
        input_group.add_option("--data-path", dest="data_path",
                          metavar="/path/IMAGE_xyz_",
                          help="Integrate files starting with this path.")
        input_group.add_option("--dark-path", dest="dark_path",
                          metavar="/path/DARK_xyz_", default=None,
                          help="Use darkcurrent files starting with this path.")
        input_group.add_option("--dark", dest="dark", default=None,
                          help="Darkcurrent image.")
        input_group.add_option("-p", "--ponit", dest="poni_file",
                          help="Name of poni file with detector geometry.")

        output_group = optparse.OptionGroup(self.parser, "Output options")
        output_group.add_option("-o", "--out", dest="outfile",
                          help="File to save integrated dataset.", metavar="FILE", default="diff_tomo.h5")
        output_group.add_option("--data-set", dest="data_set",
                          help="Location to save data set.", metavar="STRING", default="/xraylib/diff_tomo")

        self.parser.add_option_group(input_group)
        self.parser.add_option_group(output_group)

        # TODO make sure reshaping the output file is done correctly
        self.parser.add_option("--points", dest="integration_points",
                          help="Number of points to integrate azimuthally.")
        self.parser.add_option("--skip", dest="skip_file",
                          help="Skip processing to file x.",
                          metavar="x")
        self.parser.add_option("--disable-gpu",
                          action="store_true", dest="disable_gpu",
                          help="Disable GPU for integration.")
        self.parser.add_option("--disable-fast-edf",
                          action="store_true", dest="disable_fast_edf",
                          help="Disable fast reading of EDF data.")
        self.parser.add_option("--disable-threads",
                          action="store_true", dest="disable_threads",
                          help="Disable threaded loading of files.")

    @utils.Script.timed
    def parse(self):
        super(Integrator, self).parse()

        if not self.options.data_path:
            self.parser.error("Please specify the prefix for your data files")

        (data_prefix, data_directory, self.data_names) = files.matchImageFiles(self.options.data_path)
        self.files = [ os.path.join(data_directory, file_name) for file_name in self.data_names ]
        print self.files

        if self.options.dark_path is not None:
            (dark_prefix, dark_directory, dark_names) = files.matchImageFiles(self.options.dark_path)
            if len(dark_names) == 0:
                self.parser.error('No dark files found starting with %s at %s' % (dark_prefix,directory))
            self.print_verbose("--> Averaging dark images")
            self.dark = files.averageImages([ os.path.join(dark_directory, o) for o in dark_names ])

        if self.options.dark and os.path.exists(self.options.dark):
            self.dark = files.ImageFile(self.options.dark).getImage(xraylib.AVERAGE_DATA_SET)

        if len(self.files) == 0:
            self.parser.error('No data files found starting with %s at %s' % (data_prefix,directory))

        if self.options.disable_gpu is not None:
            self.disable_gpu = self.options.disable_gpu
        if self.options.disable_threads is not None:
            self.disable_threads = self.options.disable_threads
        if self.options.disable_fast_edf is not None:
            self.disable_fast_edf = self.options.disable_fast_edf

        if self.options.integration_points is not None:
            self.integration_points = self.options.integration_points

        if self.options.poni_file and os.path.exists(self.options.poni_file):
            self.integrator = pyFAI.load(self.options.poni_file)
        else:
            self.parser.error("Need poni file to set up Azimuthal integrator.")

        if self.dark is not None:
            self.integrator.darkcurrent = self.dark
        else:
            self.print_verbose("No darkcurrent provided")

        if len(self.options.data_set.split('/')) < 2:
            self.parser.error("Dataset should be on the form '/group_name/data_set'.")

        parameters = [[int(parm) for parm in os.path.splitext(o)[0].split(data_prefix)[1].split('_')
                        if parm is not '']
                      for o in self.data_names]
        parametersT = np.array(parameters).T
        print parametersT

        min_indices = parametersT.argmin(axis=1)
        max_indices = parametersT.argmax(axis=1)

        parameter_interval = np.array([ [ parametersT[i][min_indices[i]], parametersT[i][max_indices[i]] ] for i in xrange(0,parametersT.shape[0]) ])
        parameters = [(i,j-i+1) for i,j in parameter_interval]

        nframes = files.ImageFile(self.files[0]).getNFrames()
        parameters = parameters + [(0,nframes)]
        parameters = [(minVal,count) for minVal,count in parameters  if count > 1]
        self.parameter_count = [count for minVal,count in parameters ]

        self.dimensions = len(parameters)
        self.print_verbose('Number of dimensions: ', self.dimensions)


    @utils.Script.timed
    def create_dataset(self):
        self.print_verbose("--> Integrating darkcurrent")
        (two_theta, self.darkcurrent_profile) = self.integrate(self.dark)
        self.print_verbose("--> Creating dataset")


        self.print_verbose("Data set size:", tuple(self.parameter_count) + (self.integration_points,))

        self.hd5 = h5py.File(self.options.outfile)
        group = self.hd5.require_group(os.path.dirname(self.options.data_set))
        if self.options.data_set in group:
            group[self.options.data_set].resize(tuple(self.parameter_count) + (self.integration_points,))
        self.dataset = group.require_dataset(
                           name=os.path.basename(self.options.data_set),
                           shape=tuple(self.parameter_count) + (self.integration_points,),
                           chunks=tuple(self.parameter_count) + (1,),
                           dtype="float32"
        )
        darkcurrent = group.require_dataset(
                           name=xraylib.DARKCURRENT_DATA_SET,
                           shape=(self.integration_points,),
                           dtype="float32"
        )
        darkcurrent[:] = self.darkcurrent_profile

    @utils.Script.timed
    def integrate_and_assemble(self):
        if self.disable_threads:
            i=0
            for image in files.ImageSequence(self.files):
                self.integrate_single_file(i,image)
                i=i+1
            return

        self.image_queue = Queue.Queue(1)
        self.finished = False
        self.abort    = False

        intg_thread = threading.Thread(target=intg.integrate_files)
        load_thread = threading.Thread(target=intg.load_files)

        load_thread.setDaemon(True)

        intg_thread.start()
        load_thread.start()

        while(not self.finished and not self.abort):
            try:
                intg_thread.join(2)
            except KeyboardInterrupt:
                self.abort = True

        # Wait for integration thread to finish in case of aborting.
        intg_thread.join()

    def load_files(self):
        for image in files.ImageSequence(self.files):
            self.image_queue.put(image,block=True)

    def integrate_files(self):

        # load all dark-images in list

        i=0
        for index in itertools.product(*map(xrange,self.parameter_count)):
            if self.abort:
                return
            self.print_verbose("Integrating ", self.data_names[i])
            self.integrate_single_file(index, self.image_queue.get())
            self.image_queue.task_done()
            i += 1
        self.finished = True

    def integrate(self, image):
        if not self.disable_gpu:
            tth, I = self.integrator.xrpd_LUT_OCL(
                        image,
                        self.integration_points,
                        safe=False,
                        devicetype="gpu")
        else:
            tth, I = self.integrator.xrpd_LUT(image, self.integration_points, safe=False)
        return (tth,I)

    def integrate_single_file(self,index, image):
        self.print_verbose("Index ", index)
        (tth,I) =self.integrate(image)
        self.dataset[tuple(index)] = I

    @utils.Script.timed
    def output(self):
        self.hd5.close()

if __name__ == '__main__':
    intg = Integrator()

    intg.parser_setup()
    intg.parse()
    intg.create_dataset()
    intg.integrate_and_assemble()

    intg.output()
    intg.print_timings()

