#!/usr/bin/env python

import numpy as np
import os, sys, optparse, threading, Queue
import h5py, fabio

import xraylib
from xraylib import f2w, files, utils

try:
    import pyFAI
except ImportError:
    pyFAI = None

class Integrator(utils.Script):
    def __init__(self):
        super(Integrator, self).__init__()
        self.description = """
        Integrate diffraction images and assemble into dataset.
        Experiment parameters are assumed to be separated by underscore

        E.g.  NAME_xxx_yyy_zzz.edf

        will produce a data set with powder profiles in dimensions x,y,z.
        """
        self.usage="Usage: <options> --data-prefix=/mnt/data/../EXPERIMENT_..."

    def parser_setup(self):
        super(Integrator, self).parser_setup()

        input_group = optparse.OptionGroup(self.parser, "Input options")
        input_group.add_option("--data-prefix", dest="data_path",
                          metavar="/path/IMAGE_xyz_",
                          help="Integrate files starting with this path.")
        #input_group.add_option("--dark-prefix", dest="dark_prefix",
        #                  metavar="/path/DARK_xyz_",
        #                  help="Use dark noise files starting with this path.")
        input_group.add_option("--dark", dest="dark",
                          help="Dark noise image.")
        input_group.add_option("-p", "--ponit", dest="poni_file",
                          help="Name of poni file with detector geometry.")

        output_group = optparse.OptionGroup(self.parser, "Output options")
        output_group.add_option("-o", "--out", dest="outfile",
                          help="File to save integrated dataset.", metavar="FILE", default="diff_tomo.h5")
        output_group.add_option("--data-set", dest="data_set",
                          help="Location to save data set.", metavar="STRING", default="/xraylib/diff_tomo")

        self.parser.add_option_group(input_group)
        self.parser.add_option_group(output_group)

        # TODO make sure reshaping the output file is done correctly
        self.parser.add_option("--skip", dest="skip_file",
                          help="Skip processing to file x.",
                          metavar="x")
        self.parser.add_option("--disable-gpu",
                          action="store_true", dest="disable_gpu", default=False,
                          help="Disable GPU for integration.")
        self.parser.add_option("--disable-fast-edf",
                          action="store_true", dest="disable_fast_edf", default=False,
                          help="Disable fast reading of EDF data.")
        self.parser.add_option("--disable-threads",
                          action="store_true", dest="disable_threads", default=False,
                          help="Disable threaded loading of files.")

    @utils.Script.timed
    def parse(self):
        super(Integrator, self).parse()

        if not self.options.data_path:
            self.parser.error("Please specify the prefix for your data files")

        (self.directory,file_prefix) = os.path.split(os.path.expanduser(self.options.data_path))
        if self.directory == '':
            directory = '.'
        else:
            directory = self.directory
        self.file_names = [ o for o in os.listdir(directory) if o.startswith(file_prefix) and os.path.splitext(o)[1] in files.IMAGE_EXTENSIONS]
        self.files = [  os.path.join(directory,o) for o in self.file_names ]

        if ( all([os.path.splitext(file_path)[1] == '.edf'
                for file_path in self.args]) and
                not self.options.disable_fast_edf):
            self.edf_only = True
            self.print_verbose('Using fast EDF data reading')
        else:
            self.edf_only = False

        self.disable_gpu = self.options.disable_gpu
        self.disable_threads = self.options.disable_threads

        if len(self.options.data_set.split('/')) < 2:
            self.parser.error("Dataset should be on the form '/group_name/data_set'.")

        self.parameters = [ [int(parm) for parm in os.path.splitext(o)[0].split(file_prefix)[1].split('_')[1:]] for o in self.file_names ]
        parametersT = np.array(self.parameters).T

        self.number_of_parameters = parametersT.shape[0]
        self.print_verbose('Number of parameters: ', self.number_of_parameters)

        min_indices = parametersT.argmin(axis=1)
        max_indices = parametersT.argmax(axis=1)

        parameter_interval = np.array([ [ parametersT[i][min_indices[i]], parametersT[i][max_indices[i]] ] for i in xrange(0,self.number_of_parameters) ])
        self.parameter_count  = [ j-i+1 for i,j in parameter_interval ]
        self.parameter_min = parameter_interval.T[0]

        if self.options.poni_file and os.path.exists(self.options.poni_file):
            self.integrator = pyFAI.load(self.options.poni_file)
        else:
            self.parser.error("Need poni file to set up Azimuthal integrator.")

        if self.options.dark and os.path.exists(self.options.dark):
            self.dark = files.ImageFile(self.options.dark).getImage()
            # FIXME pyFAI doesn't subtract darkcurrent as of june 2013
            #self.integrator.darkcurrent = self.dark 


    @utils.Script.timed
    def create_dataset(self):
        self.print_verbose("Creating dataset")

        # FIXME remove once confirmed
        self.det = f2w.Perkin()
        self.det.setdist(900)
        self.det.setorigin(np.array([197.2052035 ,  211.88159321]))
        self.det.settilt(np.array([-0.17446037,  0.01906504]))
        (two_theta, self.darkcurrent_profile) = self.det.integrate(self.dark)

        self.print_verbose("Data set size:", (2,) + tuple(self.parameter_count) + self.darkcurrent_profile.shape,)

        self.hd5 = h5py.File(self.options.outfile)
        group = self.hd5.require_group(os.path.dirname(self.options.data_set))
        self.dataset = group.require_dataset(
                           name=os.path.basename(self.options.data_set),
                           # FIXME remove (2,) when done testing
                           shape=(2,) + tuple(self.parameter_count) + self.darkcurrent_profile.shape,
                           chunks=(2,) + tuple(self.parameter_count) + (1,),
                           dtype="float32"
                        )
        darkcurrent = group.require_dataset(
                           name=xraylib.DARKCURRENT_DATA_SET,
                           shape=self.darkcurrent_profile.shape,
                           dtype="float32"
        )
        darkcurrent[:] = self.darkcurrent_profile

    @utils.Script.timed
    def integrate_and_assemble(self):

        if self.disable_threads:
            i=0
            for image in files.ImageSequence(self.files):
                self.integrate_single_file(i,image)
                i=i+1
            return

        self.image_queue = Queue.Queue(1)
        self.finished = False
        self.abort    = False

        intg_thread = threading.Thread(target=intg.integrate_files)
        load_thread = threading.Thread(target=intg.load_files)

        load_thread.setDaemon(True)

        intg_thread.start()
        load_thread.start()

        while(not self.finished and not self.abort):
            try:
                intg_thread.join(2)
            except KeyboardInterrupt:
                self.abort = True

        # Wait for integration thread to finish in case of aborting.
        intg_thread.join()

    def load_files(self):
        for image in files.ImageSequence(self.files):
            self.image_queue.put(image,block=True)

    def integrate_files(self):
        for i in xrange(0,len(self.files)):
            if self.abort:
                return
            self.print_verbose("Integrating ", self.file_names[i])
            self.integrate_single_file(i, self.image_queue.get())
            self.image_queue.task_done()
        self.finished = True

    def integrate_single_file(self,file_number, image):
        index = self.parameters[file_number]-self.parameter_min
        self.print_verbose("Index ", index)
        (tth,result) = self.det.integrate(image)
        result = result - self.darkcurrent_profile
        self.dataset[(0,)+tuple(index)] = result.astype(np.float32)
        if not self.disable_gpu:
            tth, I = self.integrator.xrpd_LUT_OCL(
                        image-self.dark,
                        self.darkcurrent_profile.shape[0],
                        safe=False,
                        devicetype="gpu")
        else:
            tth, I = self.integrator.xrpd_LUT(image-self.dark, self.darkcurrent_profile.shape[0], safe=False)
        self.dataset[(1,)+tuple(index)] = I

    @utils.Script.timed
    def output(self):
        self.hd5.close()

if __name__ == '__main__':
    intg = Integrator()

    intg.parser_setup()
    intg.parse()
    intg.create_dataset()
    intg.integrate_and_assemble()

    intg.output()
    intg.print_timings()

